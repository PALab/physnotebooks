{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Big G Tracking**\n",
    "\n",
    "The following code will track the light for the Big G experiment. This will give you a dataset of position versus time, which you can then use to fit a curve to. \n",
    "\n",
    "To run this notebook, download it and run it as a jupyter notebook using a local instal of Anaconda. The lab computers should have all the required packages. Open an Anaconda prompt in the directory of the file and type:\n",
    "\n",
    "```jupyter notebook BigGTracking.ipynb```\n",
    "\n",
    "Details about chagning the working directory of the Anaconda prompt can be found [here](https://stackoverflow.com/questions/48304305/anaconda-python-change-anaconda-prompt-user-path). You will need to change the ```VIDEO_PATH``` variable in the second code cell to match the filename of your recorded video.\n",
    "\n",
    "## **Setup programming environment**\n",
    "\n",
    "Import the Python packages needed for our data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os.path\n",
    "import warnings\n",
    "from time import time\n",
    "\n",
    "# Third party imports\n",
    "import cv2\n",
    "from IPython.display import display, HTML\n",
    "from ipywidgets import FloatProgress\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.odr import ODR, RealData, Model\n",
    "from uncertainties import ufloat\n",
    "import uncertainties.umath as umath\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare all our *global* variables. These are variables needed by multiple cells. They will be indicated using UPPER CASE letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_PATH = './video.mp4' # Path to the video file for analysis\n",
    "FIRST_FRAME_IMAGE = None   # Image of the first video frame\n",
    "U_DISTANCE = None          # Uncertain distance (in pixels) of the scale line\n",
    "BOX = None                 # The bounding box for the object to be tracked\n",
    "U_POSITION = None          # Uncertain position of the object tracker\n",
    "FIT = None                 # The parameters for the curve fit to object tracking data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preview video (optional)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(VIDEO_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Set the video scale**\n",
    "\n",
    "This provides a plot in which a user can select endpoints of a line. This line should represent a known distance in the real world and will be used to translate movement in the video into accurate positional data.\n",
    "\n",
    "Currently, the recommended way to draw the best line is to:\n",
    "  1. turn on the zoom tool\n",
    "  2. drag a box around the entire scale object\n",
    "  3. turn off the zoom tool\n",
    "  4. click one end of the scale object\n",
    "  5. click the other end of the scale object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "ax.set_title('Pixel distance: ?')\n",
    "line = ax.plot([0, 200], [0, 200])[0]\n",
    "video = cv2.VideoCapture(VIDEO_PATH)\n",
    "FIRST_FRAME_IMAGE = cv2.cvtColor(video.read()[1], cv2.COLOR_BGR2RGB) # Image of the first video frame\n",
    "video.release()\n",
    "ax.imshow(FIRST_FRAME_IMAGE)\n",
    "\n",
    "switch = True\n",
    "\n",
    "def onclickline(event): # this runs each mouse click\n",
    "    global switch, U_DISTANCE\n",
    "    # get current line\n",
    "    (x0, x1), (y0, y1) = line.get_data()\n",
    "    # alternate which endpoint of the line gets changed\n",
    "    switch = not switch\n",
    "    if switch: # change first point\n",
    "        line.set_data([event.xdata, x1], [event.ydata, y1])\n",
    "    else: # change second point\n",
    "        line.set_data([x0, event.xdata], [y0, event.ydata])\n",
    "    # get updated line data\n",
    "    (x0, x1), (y0, y1) = line.get_data()\n",
    "    # convert data coordinate (0,0) to display coordinate\n",
    "    display_x, display_y = ax.transData.transform((0, 0))\n",
    "    # convert display coordinate (1,1) to data coordinate\n",
    "    ux, uy = ax.transData.inverted().transform((display_x+1, display_y+1))\n",
    "    ux0 = ufloat(x0, abs(ux/2), \"mouse_click_1x\")\n",
    "    uy0 = ufloat(y0, abs(uy/2), \"mouse_click_1y\")\n",
    "    ux1 = ufloat(x1, abs(ux/2), \"mouse_click_2x\")\n",
    "    uy1 = ufloat(y1, abs(uy/2), \"mouse_click_2y\")\n",
    "    U_DISTANCE = umath.sqrt(umath.pow(ux1-ux0, 2) + umath.pow(uy1-uy0, 2))\n",
    "    ax.set_title('Pixel distance: {}'.format(U_DISTANCE))\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclickline)\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having drawn a scale line, this will ask the user what distance the line represents and will also ask for the uncertainty in this distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure = float(input('The line drawn has a distance of {:.2f} pixels.\\n'.format(U_DISTANCE.n)\n",
    "                      + 'Tell me how many metres this should represent: '))\n",
    "std_dev = float(input('What is the uncertainty of this length:'))\n",
    "scale = ufloat(measure, std_dev, \"scale_object_measurement\") / U_DISTANCE\n",
    "print('Each pixel will be {} metres.'.format(scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Mark the object to be tracked**\n",
    "\n",
    "The user should now create a bounding box around the object to be tracked. A plot will be presented with the first video frame displayed. Mouse clicks will alternate between relocating the upper left and lower right corners of the bounding box.\n",
    "\n",
    "Currently, the recommended way to draw the best box is to:\n",
    "  1. turn on the zoom tool\n",
    "  2. drag a box around the object to be tracked\n",
    "  3. turn off the zoom tool\n",
    "  4. click the upper left corner of the desired bounding box\n",
    "  5. click the lower right corner of the desired bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "BOX = ax.plot([200, 400, 400, 200, 200], [200, 200, 400, 400, 200])[0]\n",
    "ax.imshow(FIRST_FRAME_IMAGE)\n",
    "\n",
    "switch = True\n",
    "\n",
    "def onclickbox(event):\n",
    "    global switch, BOX\n",
    "    xs, ys = BOX.get_data()\n",
    "    if switch:\n",
    "        BOX.set_data([event.xdata, xs[1], xs[2], event.xdata, event.xdata],\n",
    "                     [event.ydata, event.ydata, ys[2], ys[3], event.ydata])\n",
    "    else:\n",
    "        BOX.set_data([xs[0], event.xdata, event.xdata, xs[3], xs[0]],\n",
    "                     [ys[0], ys[1], event.ydata, event.ydata, ys[0]])\n",
    "    switch = not switch\n",
    "    fig.canvas.draw_idle()\n",
    "    \n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclickbox)\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Perform object tracking**\n",
    "\n",
    "The bounding box selected is fed into the object tracker and the position of the object inside the bounding box is recording through time.\n",
    "\n",
    "A progress bar is provided to monitor the object tracking.\n",
    "\n",
    "*Please do not move to the next step until object tracking completes. It will take several minutes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(VIDEO_PATH)\n",
    "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "progress = FloatProgress(min=0, max=total_frames)\n",
    "display(progress)\n",
    "try:\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    first_frame = video.read()[1]\n",
    "    tracker = cv2.TrackerMIL_create()\n",
    "    xs, ys = BOX.get_data()\n",
    "    bbox = min(xs[0],xs[2]), min(ys[0],ys[2]), abs(xs[2]-xs[0]), abs(ys[2]-ys[0])\n",
    "    origin = ((2.0 * bbox[0] + bbox[2]) / 2.0,\n",
    "              (2.0 * bbox[1] + bbox[3]) / 2.0)\n",
    "    success = tracker.init(first_frame, bbox)\n",
    "    if not success:\n",
    "        raise RuntimeError('could not initialize tracker')\n",
    "    frame_number = 0\n",
    "    OBJECT_TRACKING_X = [ufloat(frame_number/fps, 0.5/fps, \"time\")]\n",
    "    OBJECT_TRACKING_Y = [ufloat(0, scale.std_dev, \"scale\")]\n",
    "    while True:\n",
    "        success, frame = video.read()\n",
    "        if not success:\n",
    "            break\n",
    "        frame_number += 1\n",
    "        progress.value += 1\n",
    "        success, bbox = tracker.update(frame)\n",
    "        if success:\n",
    "            distance = np.sqrt((((2.0 * bbox[0] + bbox[2]) / 2.0) - origin[0])**2\n",
    "                               + (((2.0 * bbox[1] + bbox[3]) / 2.0) - origin[1])**2)\n",
    "            OBJECT_TRACKING_X.append(ufloat(frame_number/fps, 0.5/fps, \"time\"))\n",
    "            OBJECT_TRACKING_Y.append(distance * scale)\n",
    "finally:\n",
    "    video.release()\n",
    "    del video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the **progress bar above** is completely blue, You will now be able to plot the tracked object position against time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plot our object tracking data\n",
    "plt.plot([x.n for x in OBJECT_TRACKING_X], [y.n for y in OBJECT_TRACKING_Y])\n",
    "plt.title('Position of tracked object')\n",
    "plt.xlabel('seconds')\n",
    "plt.ylabel('metres')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tracked_data.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Time (s)','Position (m)'])\n",
    "    time = list([x.n for x in OBJECT_TRACKING_X])\n",
    "    pos = list([y.n for y in OBJECT_TRACKING_Y])\n",
    "    for i in range(len(time)):\n",
    "        writer.writerow([time[i],pos[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
